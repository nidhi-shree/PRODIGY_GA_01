# GPT-2 Short Story Training

This repository contains a Colab notebook for training a GPT-2 model on a collection of short stories.

## Files

- `model_training.ipynb` – Notebook with data preprocessing, model training, and evaluation.
- `preprocessed_data.csv` – Preprocessed dataset used for training.

## Dataset

The dataset used is from [Kaggle: Poe Short Stories Corpus](https://www.kaggle.com/datasets/leangab/poe-short-stories-corpuscsv).

## How to Use

1. Open the notebook in Google Colab.
2. Run the cells sequentially to preprocess the data and train the GPT-2 model.
3. Check training and validation loss graphs for model evaluation.

## License

This project is for learning purposes.
